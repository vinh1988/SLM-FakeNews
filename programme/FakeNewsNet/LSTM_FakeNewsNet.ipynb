{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPi8/46Z6RZmrYaFrM8vWpZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"dc9c69d98bf9447084f2e664686df3ca":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_65e1cef1e7304e1180d11e3ccaf74e53","IPY_MODEL_7de9db5a1d034797993ebefac3a30b1e","IPY_MODEL_071fb5e006c740f392673bdb89252df6"],"layout":"IPY_MODEL_f6eed36735c34a8e98defa7a2cfd7523"}},"65e1cef1e7304e1180d11e3ccaf74e53":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90755dfe2add4b189528490d22d9734f","placeholder":"‚Äã","style":"IPY_MODEL_0ee54d5303104054b2e51d83a9c4f02f","value":"README.md:‚Äá100%"}},"7de9db5a1d034797993ebefac3a30b1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_14211789f8d443ba8c9b435ce9742e35","max":23,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad753dc1523e4c5eab870b8857365882","value":23}},"071fb5e006c740f392673bdb89252df6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9dc276383cb94790a27a56836c271118","placeholder":"‚Äã","style":"IPY_MODEL_edccfd70152a4770b9a820ed54c8b2b0","value":"‚Äá23.0/23.0‚Äá[00:00&lt;00:00,‚Äá1.74kB/s]"}},"f6eed36735c34a8e98defa7a2cfd7523":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90755dfe2add4b189528490d22d9734f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ee54d5303104054b2e51d83a9c4f02f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"14211789f8d443ba8c9b435ce9742e35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad753dc1523e4c5eab870b8857365882":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9dc276383cb94790a27a56836c271118":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"edccfd70152a4770b9a820ed54c8b2b0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"134d253d704c4738867f39ece676014f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d7dbaff2210a41898df0ff58d6195192","IPY_MODEL_73cbffaaf09445f38b8061a6fc2ce338","IPY_MODEL_f1989e889c774fbdaa882b76e2c15661"],"layout":"IPY_MODEL_2cac77c41d5d4fbb9af6ed0d2b37851d"}},"d7dbaff2210a41898df0ff58d6195192":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_99963ce5943d41a28d40ea9532e0539a","placeholder":"‚Äã","style":"IPY_MODEL_9d919fbcb0574c2cae4e2efd2e174bc2","value":"FakeNewsNet.csv:‚Äá"}},"73cbffaaf09445f38b8061a6fc2ce338":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_05bc6afafde246b99a88304218cb90ce","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd535433c14a4cebb790b56a13c57e4d","value":1}},"f1989e889c774fbdaa882b76e2c15661":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64dd6a9a76c84d878e7d054400c0776a","placeholder":"‚Äã","style":"IPY_MODEL_2a4b035c7281490eb214b3ad7a422f2c","value":"‚Äá4.31M/?‚Äá[00:00&lt;00:00,‚Äá70.1MB/s]"}},"2cac77c41d5d4fbb9af6ed0d2b37851d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"99963ce5943d41a28d40ea9532e0539a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d919fbcb0574c2cae4e2efd2e174bc2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"05bc6afafde246b99a88304218cb90ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"bd535433c14a4cebb790b56a13c57e4d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"64dd6a9a76c84d878e7d054400c0776a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2a4b035c7281490eb214b3ad7a422f2c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e2556755c1b743cdb32a6b5bd661a327":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7a7a965df25d476e8597724e9451b278","IPY_MODEL_81ca602a5e6a4beaa297b0a2564e268a","IPY_MODEL_dab2b6daf2234c909c133d7120a03240"],"layout":"IPY_MODEL_be08e869e2894113a00164ed4ca73641"}},"7a7a965df25d476e8597724e9451b278":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_41b16dc877ff4a9d802d859e8ab2e150","placeholder":"‚Äã","style":"IPY_MODEL_2c9206eb8c9b4a67bf980b686984e167","value":"Generating‚Äátrain‚Äásplit:‚Äá100%"}},"81ca602a5e6a4beaa297b0a2564e268a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3632cd6cd7ed4679bfbef91c094d7c02","max":23196,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e03ae60558ab432ca2a0590242a2b126","value":23196}},"dab2b6daf2234c909c133d7120a03240":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f016b3122c9543f0a6b6710d30d0fd3a","placeholder":"‚Äã","style":"IPY_MODEL_cb156d34ed8049f1bbc97df18c03e5b1","value":"‚Äá23196/23196‚Äá[00:00&lt;00:00,‚Äá172998.20‚Äáexamples/s]"}},"be08e869e2894113a00164ed4ca73641":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41b16dc877ff4a9d802d859e8ab2e150":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c9206eb8c9b4a67bf980b686984e167":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3632cd6cd7ed4679bfbef91c094d7c02":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e03ae60558ab432ca2a0590242a2b126":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f016b3122c9543f0a6b6710d30d0fd3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb156d34ed8049f1bbc97df18c03e5b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":754,"referenced_widgets":["dc9c69d98bf9447084f2e664686df3ca","65e1cef1e7304e1180d11e3ccaf74e53","7de9db5a1d034797993ebefac3a30b1e","071fb5e006c740f392673bdb89252df6","f6eed36735c34a8e98defa7a2cfd7523","90755dfe2add4b189528490d22d9734f","0ee54d5303104054b2e51d83a9c4f02f","14211789f8d443ba8c9b435ce9742e35","ad753dc1523e4c5eab870b8857365882","9dc276383cb94790a27a56836c271118","edccfd70152a4770b9a820ed54c8b2b0","134d253d704c4738867f39ece676014f","d7dbaff2210a41898df0ff58d6195192","73cbffaaf09445f38b8061a6fc2ce338","f1989e889c774fbdaa882b76e2c15661","2cac77c41d5d4fbb9af6ed0d2b37851d","99963ce5943d41a28d40ea9532e0539a","9d919fbcb0574c2cae4e2efd2e174bc2","05bc6afafde246b99a88304218cb90ce","bd535433c14a4cebb790b56a13c57e4d","64dd6a9a76c84d878e7d054400c0776a","2a4b035c7281490eb214b3ad7a422f2c","e2556755c1b743cdb32a6b5bd661a327","7a7a965df25d476e8597724e9451b278","81ca602a5e6a4beaa297b0a2564e268a","dab2b6daf2234c909c133d7120a03240","be08e869e2894113a00164ed4ca73641","41b16dc877ff4a9d802d859e8ab2e150","2c9206eb8c9b4a67bf980b686984e167","3632cd6cd7ed4679bfbef91c094d7c02","e03ae60558ab432ca2a0590242a2b126","f016b3122c9543f0a6b6710d30d0fd3a","cb156d34ed8049f1bbc97df18c03e5b1"]},"id":"sSWw63tpF-72","executionInfo":{"status":"ok","timestamp":1764511843205,"user_tz":-420,"elapsed":112700,"user":{"displayName":"phan khac lap","userId":"11609788902879711168"}},"outputId":"9b79c99a-173f-4ffe-8a4f-6e6ecef52995"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Device: cuda\n","\n","‚è≥ ƒêang t·∫£i dataset FakeNewsNet...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["README.md:   0%|          | 0.00/23.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dc9c69d98bf9447084f2e664686df3ca"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["‚ö†Ô∏è T·∫£i config con th·∫•t b·∫°i (BuilderConfig 'gossipcop' not found. Available: ['default']), t·∫£i b·∫£n default...\n"]},{"output_type":"display_data","data":{"text/plain":["FakeNewsNet.csv: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"134d253d704c4738867f39ece676014f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating train split:   0%|          | 0/23196 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2556755c1b743cdb32a6b5bd661a327"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["üßπ Pre-processing...\n","Train: 14700 | Test: 3675\n","\n","‚öôÔ∏è X√¢y d·ª±ng b·ªô t·ª´ v·ª±ng...\n","\n","üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán LSTM (FakeNewsNet)...\n","Epoch 01 | Time: 9s | Train Loss: 0.301 | Train Acc: 66.89%\n","Epoch 02 | Time: 8s | Train Loss: 0.250 | Train Acc: 77.40%\n","Epoch 03 | Time: 8s | Train Loss: 0.220 | Train Acc: 80.38%\n","Epoch 04 | Time: 8s | Train Loss: 0.197 | Train Acc: 82.19%\n","Epoch 05 | Time: 8s | Train Loss: 0.174 | Train Acc: 84.42%\n","Epoch 06 | Time: 8s | Train Loss: 0.156 | Train Acc: 85.68%\n","Epoch 07 | Time: 8s | Train Loss: 0.133 | Train Acc: 87.85%\n","Epoch 08 | Time: 8s | Train Loss: 0.120 | Train Acc: 89.36%\n","\n","üéØ ƒêANG ƒê√ÅNH GI√Å (TEST SET)...\n","\n","==================================================\n","üìä K·∫æT QU·∫¢ LSTM BASELINE - FAKENEWSNET:\n","==================================================\n","{'eval_accuracy': 0.7787755102040816, 'eval_precision': 0.8121835858216199, 'eval_recall': 0.7787755102040816, 'eval_f1': 0.7889353729807991, 'eval_auc': np.float64(0.8483959457909259), 'eval_loss': 'N/A', 'eval_runtime': 0.860276460647583, 'eval_samples_per_second': 4271.8825495162355}\n","==================================================\n","‚úÖ ƒê√£ l∆∞u model!\n"]}],"source":["# =====================================================\n","# BASELINE: LSTM (Bi-directional) - FAKENEWSNET\n","# Framework: PyTorch\n","# =====================================================\n","\n","import os, re, time, pickle, psutil\n","import pandas as pd\n","import numpy as np\n","from collections import Counter\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from datasets import load_dataset, concatenate_datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n","from google.colab import drive\n","\n","# 1. SETUP & CONFIG\n","if not os.path.exists('/content/drive'):\n","    try:\n","        drive.mount('/content/drive', force_remount=True)\n","    except ValueError: pass\n","\n","OUTPUT_DIR = \"/content/drive/MyDrive/FakeNewsNet_LSTM_Baseline\"\n","os.makedirs(OUTPUT_DIR, exist_ok=True)\n","\n","# Hyperparameters (T·ªëi ∆∞u cho vƒÉn b·∫£n d√†i c·ªßa FakeNewsNet)\n","MAX_VOCAB_SIZE = 25000  # TƒÉng vocab size v√¨ b√†i b√°o ƒëa d·∫°ng t·ª´ v·ª±ng\n","MAX_SEQ_LEN = 300       # Gi·ªØ 300 t·ª´ ƒë·∫ßu ti√™n (ƒë·ªß ƒë·ªÉ n·∫Øm √Ω ch√≠nh)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 128\n","BATCH_SIZE = 64\n","EPOCHS = 8\n","LEARNING_RATE = 0.001\n","DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","print(f\"Device: {DEVICE}\")\n","\n","# 2. LOAD DATA\n","print(\"\\n‚è≥ ƒêang t·∫£i dataset FakeNewsNet...\")\n","try:\n","    ds_gossip = load_dataset(\"rickstello/FakeNewsNet\", \"gossipcop\", split=\"train\")\n","    ds_politi = load_dataset(\"rickstello/FakeNewsNet\", \"politifact\", split=\"train\")\n","    dataset_full = concatenate_datasets([ds_gossip, ds_politi])\n","    df = pd.DataFrame(dataset_full)\n","except Exception as e:\n","    print(f\"‚ö†Ô∏è T·∫£i config con th·∫•t b·∫°i ({e}), t·∫£i b·∫£n default...\")\n","    dataset = load_dataset(\"rickstello/FakeNewsNet\", split=\"train\")\n","    df = pd.DataFrame(dataset)\n","\n","# 3. PRE-PROCESSING\n","# A. T√¨m t√™n c·ªôt an to√†n\n","text_col = next((c for c in ['news_content', 'text', 'content', 'body'] if c in df.columns), None)\n","title_col = next((c for c in ['title', 'news_title', 'headline'] if c in df.columns), None)\n","label_col = next((c for c in ['real', 'label', 'class', 'fake'] if c in df.columns), None)\n","\n","if not label_col: raise ValueError(\"‚ùå Kh√¥ng t√¨m th·∫•y c·ªôt nh√£n!\")\n","\n","# B. X·ª≠ l√Ω d·ªØ li·ªáu\n","text_data = df[text_col].fillna('') if text_col else pd.Series([\"\"] * len(df))\n","title_data = df[title_col].fillna('') if title_col else pd.Series([\"\"] * len(df))\n","df['label'] = df[label_col].astype(int)\n","\n","# C. Clean Text (Deep Learning Style)\n","def clean_text_dl(s):\n","    if not isinstance(s, str): return \"\"\n","    s = s.lower()\n","    s = re.sub(r'https?://\\S+', '', s)\n","    s = re.sub(r'<.*?>', '', s)\n","    s = re.sub(r'[^a-z0-9\\s]', '', s) # Gi·ªØ l·∫°i ch·ªØ v√† s·ªë\n","    s = re.sub(r'\\s+', ' ', s).strip()\n","    return s\n","\n","print(\"üßπ Pre-processing...\")\n","# Gh√©p Title + Text: Title th∆∞·ªùng ch·ª©a th√¥ng tin quan tr·ªçng nh·∫•t (clickbait)\n","df['content'] = (title_data + \" \" + text_data).apply(clean_text_dl)\n","df = df[df['content'].str.len() > 50] # L·ªçc b·ªè m·∫´u r√°c\n","\n","# 4. SPLIT DATA\n","X_train_text, X_test_text, y_train, y_test = train_test_split(\n","    df['content'].values, df['label'].values, test_size=0.2, random_state=42, stratify=df['label']\n",")\n","\n","print(f\"Train: {len(X_train_text)} | Test: {len(X_test_text)}\")\n","\n","# 5. VOCABULARY & TOKENIZATION\n","print(\"\\n‚öôÔ∏è X√¢y d·ª±ng b·ªô t·ª´ v·ª±ng...\")\n","word_counts = Counter()\n","for text in X_train_text:\n","    word_counts.update(text.split())\n","\n","common_words = word_counts.most_common(MAX_VOCAB_SIZE - 2)\n","vocab = {word: i+2 for i, (word, _) in enumerate(common_words)}\n","vocab['<PAD>'] = 0\n","vocab['<UNK>'] = 1\n","\n","def encode_text(text, vocab, max_len):\n","    tokens = text.split()\n","    encoded = [vocab.get(token, vocab['<UNK>']) for token in tokens]\n","    if len(encoded) > max_len:\n","        encoded = encoded[:max_len]\n","    else:\n","        encoded = encoded + [vocab['<PAD>']] * (max_len - len(encoded))\n","    return encoded\n","\n","# 6. DATASET & DATALOADER\n","class FnnDataset(Dataset):\n","    def __init__(self, texts, labels, vocab, max_len):\n","        self.texts = texts\n","        self.labels = labels\n","        self.vocab = vocab\n","        self.max_len = max_len\n","\n","    def __len__(self): return len(self.texts)\n","\n","    def __getitem__(self, idx):\n","        text = self.texts[idx]\n","        label = self.labels[idx]\n","        encoded = encode_text(text, self.vocab, self.max_len)\n","        return torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.float)\n","\n","train_ds = FnnDataset(X_train_text, y_train, vocab, MAX_SEQ_LEN)\n","test_ds  = FnnDataset(X_test_text, y_test, vocab, MAX_SEQ_LEN)\n","\n","train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n","test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE * 2, shuffle=False)\n","\n","# 7. MODEL ARCHITECTURE (Bi-LSTM)\n","class LSTMClassifier(nn.Module):\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n","                            bidirectional=bidirectional, batch_first=True, dropout=dropout)\n","        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, text):\n","        embedded = self.dropout(self.embedding(text))\n","        output, (hidden, cell) = self.lstm(embedded)\n","        if self.lstm.bidirectional:\n","            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n","        else:\n","            hidden = self.dropout(hidden[-1,:,:])\n","        return self.fc(hidden)\n","\n","model = LSTMClassifier(len(vocab), EMBEDDING_DIM, HIDDEN_DIM, 1, 2, True, 0.3).to(DEVICE)\n","\n","# T√≠nh class weight cho Loss function (v√¨ FNN m·∫•t c√¢n b·∫±ng)\n","num_pos = sum(y_train)\n","num_neg = len(y_train) - num_pos\n","pos_weight = torch.tensor([num_neg / num_pos]).to(DEVICE) # Tr·ªçng s·ªë cho l·ªõp Positive (Real)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n","\n","# 8. TRAINING LOOP\n","def binary_accuracy(preds, y):\n","    rounded_preds = torch.round(torch.sigmoid(preds))\n","    correct = (rounded_preds == y).float()\n","    return correct.sum() / len(correct)\n","\n","print(f\"\\nüöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán LSTM (FakeNewsNet)...\")\n","\n","for epoch in range(EPOCHS):\n","    start_t = time.time()\n","    model.train()\n","    train_loss, train_acc = 0, 0\n","\n","    for text, label in train_loader:\n","        text, label = text.to(DEVICE), label.to(DEVICE)\n","        optimizer.zero_grad()\n","        predictions = model(text).squeeze(1)\n","        loss = criterion(predictions, label)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item()\n","        train_acc += binary_accuracy(predictions, label).item()\n","\n","    end_t = time.time()\n","    print(f'Epoch {epoch+1:02} | Time: {int(end_t-start_t)}s | '\n","          f'Train Loss: {train_loss/len(train_loader):.3f} | Train Acc: {train_acc/len(train_loader)*100:.2f}%')\n","\n","# 9. EVALUATION (HuggingFace Style)\n","print(\"\\nüéØ ƒêANG ƒê√ÅNH GI√Å (TEST SET)...\")\n","model.eval()\n","all_preds, all_labels, all_probs = [], [], []\n","\n","start_eval = time.time()\n","with torch.no_grad():\n","    for text, label in test_loader:\n","        text, label = text.to(DEVICE), label.to(DEVICE)\n","        predictions = model(text).squeeze(1)\n","        prob = torch.sigmoid(predictions)\n","        all_probs.extend(prob.cpu().numpy())\n","        all_preds.extend(torch.round(prob).cpu().numpy())\n","        all_labels.extend(label.cpu().numpy())\n","\n","runtime = time.time() - start_eval\n","samples_per_second = len(all_labels) / runtime\n","\n","accuracy = accuracy_score(all_labels, all_preds)\n","precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted')\n","auc = roc_auc_score(all_labels, all_probs)\n","\n","eval_results = {\n","    'eval_accuracy': accuracy,\n","    'eval_precision': precision,\n","    'eval_recall': recall,\n","    'eval_f1': f1,\n","    'eval_auc': auc,\n","    'eval_loss': 'N/A',\n","    'eval_runtime': runtime,\n","    'eval_samples_per_second': samples_per_second\n","}\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\"üìä K·∫æT QU·∫¢ LSTM BASELINE - FAKENEWSNET:\")\n","print(\"=\"*50)\n","print(eval_results)\n","print(\"=\"*50)\n","\n","# 10. SAVE\n","torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"lstm_fnn_model.pth\"))\n","with open(os.path.join(OUTPUT_DIR, \"vocab_fnn.pkl\"), \"wb\") as f:\n","    pickle.dump(vocab, f)\n","print(\"‚úÖ ƒê√£ l∆∞u model!\")"]}]}