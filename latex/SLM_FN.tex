\documentclass[runningheads]{llncs}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{times}
\usepackage{amsmath, amssymb}
\usepackage{graphicx}
\usepackage{url}
\usepackage{cite}
\usepackage{booktabs}
\usepackage{multirow} 
\usepackage{caption}  
\usepackage{subcaption}
\usepackage{enumitem}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{amsmath} 
\usepackage{float}
\usepackage[unicode]{hyperref}

\usepackage{tikz}
\usetikzlibrary{shapes.geometric, arrows, positioning, fit, calc, backgrounds}

\title{An Approach Based on Fine-tuning Small Language Models for Fake News Detection}

\author{Khac-Lap Phan\inst{1}\and{Quang-Vinh Pham}\inst{2} \and Quang-Hung Le\inst{3}$^*$\\
    Address:  \textit{Dept. of Information Technology, Quy Nhon University, Vietnam} \inst{1, 3}\\
	\textit{TMA Tech Group, Gia Lai, Vietnam} \inst{2}\\
    Email: \email{lap4654100006@st.qnu.edu.vn}\inst{1}, \email{pqvinh@tma.com.vn}\inst{2}, \email{lequanghung@qnu.edu.vn}\inst{3}$^*$}

\authorrunning{Phan et al.}

\institute{}

% Set up running title and headers
\makeatletter
\def\@runningtitle{\textsc{Fine-tuning Small Language Models for Fake News Detection}}
\markboth{\textsc{Khac-Lap Phan et~al.}}{\@runningtitle}
\def\ps@headings{%
    \def\@oddfoot{}\def\@evenfoot{}%
    \def\@evenhead{\textsc{\leftmark}\hfill\thepage}% Small caps author + page number
    \def\@oddhead{\thepage\hfill\textsc{\rightmark}}% Page number + small caps title
    \let\@mkboth\markboth
    \def\sectionmark##1{\markboth{\textsc{Khac-Lap Phan et~al.}}{\@runningtitle}}}
\pagestyle{headings}
\makeatother

\begin{document}
	\maketitle
	
	{
		\renewcommand{\thefootnote}{} 
		\footnotetext{
			\noindent $^*$ Corresponding author: Quang-Hung Le (\url{lequanghung@qnu.edu.vn})\\
			\inst{1}\url{https://github.com/PhanKhacLapQNU/SLM_FakeNews}
		}
	}
	
	\begin{abstract}
		The proliferation of digital misinformation necessitates efficient and scalable detection mechanisms. While Large Language Models (LLMs) offer superior performance, their deployment is constrained by substantial latency and resource demands. This study proposes a unified framework leveraging Small Language Models (SLMs) specifically DistilBERT, MiniLM, and ALBERT enhanced by diverse Parameter-Efficient Fine-Tuning (PEFT) strategies, including Low-Rank Adaptation (LoRA), Bottleneck Adapters, and Prompt Tuning. We conduct a rigorous evaluation across three benchmarks representing distinct challenges: WELFake (large-scale balanced), FakeNewsNet (highly imbalanced), and LIAR (short-text).
		
		Our results reveal three critical insights: (1) On long-form articles (WELFake), SLMs match or surprisingly outperform teacher models; notably, DistilBERT (Full FT) achieved a state-of-the-art $F_{1}$-score of 99.09\%, surpassing RoBERTa-base. (2) MiniLM emerges as the efficiency sweet spot, offering comparable accuracy with a 2.7$\times$ speedup suitable for real-time edge deployment. (3) Most significantly, we identify a "Model Collapse" phenomenon on the short-text LIAR dataset, where Full Fine-Tuning and LoRA failed to generalize ($F_{1} \approx 45.7\%$). However, Bottleneck Adapters proved exceptionally robust in this context, recovering performance to $\sim$68\% and outperforming the BERT-base teacher. These findings validate SLMs as a robust solution for automated fact-checking and highlight the critical role of structural adaptation (Adapters) in handling noisy, context-sparse data.
		
	\end{abstract}
	\keywords{fake news detection \and small language models \and NLP \and efficiency \and DistilBERT \and MiniLM \and LoRA \and prompt tuning \and adapters \and edge computing.}

	
	\section{Introduction}
	In todayâ€™s digital age, fake news and misinformation have evolved into a major threat, spreading rapidly across social media platforms such as Facebook, TikTok, and Twitter~\cite{vosoughi2018spread}. This proliferation poses significant social challenges, exacerbating issues ranging from the erosion of public trust to severe health crises~\cite{shu2017fake,allcott2017social}. A prime example is the COVID-19 pandemic, where rumors about vaccines and conspiracy theories caused widespread confusion and misguided decisions affecting public health~\cite{zarocostas2020fight}. According to the World Health Organization (WHO), such misinformation can spread faster than the virus itself, undermining social stability~\cite{who2020mythbusters}. Consequently, detecting fake news utilizing machine learning and natural language processing (NLP) has become a critical research area~\cite{oshikawa2018survey}.
	
	Despite their high accuracy, Large Language Models (LLMs) like GPT-4 and BERT impose significant computational costs, high latency, and substantial memory requirements. These constraints hinder their deployment on edge devices or resource-constrained servers, particularly in regions with uneven technological infrastructure~\cite{devlin2019bert,openai2023gpt4}. To address these limitations, Small Language Models (SLMs) developed via knowledge distillation offer a lightweight alternative, aiming to maintain competitive performance while reducing resource consumption~\cite{hinton2015distilling, sanh2019distilbert}.
	
	The core challenge lies in accurately detecting fake news while preserving computational efficiency~\cite{li2023survey}. We must strike a balance between model performance minimizing misclassification and practical deployability, where inference speed and memory footprint are critical. The objective of this study is to develop and evaluate a Small Language Models-Based Approach for Fake News Detection, analyzing the trade-offs between accuracy, efficiency, and scalability.
	
	Our main contributions are summarized as follows:
	\begin{enumerate}
		\item We propose a fine-tuning pipeline for diverse SLM architectures (DistilBERT, MiniLM, ALBERT) on the WELFake, FakeNewsNet and Liar dataset to evaluate their efficacy in fake news detection.
		\item We conduct a comprehensive comparative analysis against the standard BERT-base baseline, demonstrating that SLMs can achieve near-state-of-the-art accuracy.
		\item We provide a detailed analysis of the trade-offs between parameter size, inference latency, and accuracy, offering practical insights for real-world deployment in resource-constrained environments.
	\end{enumerate}
	
	The remainder of this paper is organized as follows: Section 2 reviews the background and related work. Section 3 details our methodology and the proposed SLM-based pipeline. Section 4 describes the experimental setup, including datasets and baselines. Section 5 presents the experimental results and a discussion on the efficiency trade-offs. Finally, Section 6 concludes the paper and outlines future research directions.
	
	\section{Background and Related Work}
	
	This section outlines the formal definition of the fake news detection task, reviews existing detection techniques ranging from traditional machine learning to large pre-trained models, and introduces Small Language Models (SLMs) as an efficient alternative. Finally, we identify the research gap that motivates this study.
	
	\subsection{Task Formulation}
	Let $\mathcal{D}=\{(x_{i},y_{i})\}_{i=1}^{N}$ denote a labeled dataset of news articles, headlines, or short text segments, where:
	\begin{itemize}[label=\textbullet]
		\item $x_{i}$ represents a textual instance (e.g., full article text, headline-body pair, or social media post),
		\item $y_{i}\in\{0,1\}$ denotes the corresponding label, with 0 indicating real news and 1 indicating fake news,
		\item $N$ is the total number of examples.
	\end{itemize}
	
	The objective is to learn a mapping function
	\begin{equation}
		f_{\theta}:X\rightarrow Y
	\end{equation}
	parameterized by $\theta$, such that the predicted labels $\hat{y}_{i}=f_{\theta}(x_{i})$ approximate the true labels $y_{i}$ as closely as possible.
	During training, the model minimizes a loss function typically binary cross-entropy over the dataset:
	\begin{equation}
		\mathcal{L}(\theta)=-\sum_{i=1}^{N}[y_{i}\log\hat{y}_{i}+(1-y_{i})\log(1-\hat{y}_{i})].
	\end{equation}
	The trained model is then evaluated on unseen data to measure its ability to generalize to new or previously unobserved news content.
	
	\subsection{Fake News Detection Techniques}
	Research in fake news detection has evolved significantly, shifting from hand-crafted features to deep semantic representations.
	
	Early approaches relied on traditional machine learning, extracting hand-crafted features such as TF-IDF vectors and applying classifiers including SVM, Naive Bayes, or Random Forest~\cite{shu2017fake, ruchansky2017csi}. While effective for simple tasks, these methods often fail to capture complex semantic dependencies. Deep learning models such as CNN and LSTM addressed some of these limitations by capturing sequential patterns and achieving improved performance~\cite{wang2018eann, singhania20193han}.
	
	More recently, Transformer-based and pre-trained language models (PLMs) have become dominant due to their contextual understanding capabilities~\cite{yang2022fake, liu2019roberta}. BERT and RoBERTa, along with their variants, have been widely applied to text classification and misinformation detection by fine-tuning on domain-specific data~\cite{devlin2019bert, liu2019roberta}. RoBERTa often outperforms BERT due to larger training corpora and optimized pre-training. However, large language models (LLMs) such as GPT-3, GPT-4, and T5 demand substantial computational resources, rendering them impractical for resource-limited environments~\cite{raffel2020t5, openai2023gpt4}.
	
	\subsection{Small Language Models (SLMs)}
	To address the inefficiency of LLMs, Small Language Models (SLMs) have emerged as a viable solution. SLMs are compact models, typically containing fewer than 500 million parameters, designed to retain strong language understanding capabilities while significantly reducing computational costs.
	
	SLMs are generally derived from larger models via three primary model compression techniques:
	\begin{itemize}[label=\textbullet]
		\item Knowledge Distillation: A teacher-student framework where a smaller student model learns to mimic the behavior (logits or hidden states) of a larger teacher model~\cite{hinton2015distilling}.
		\item Pruning: The removal of less important weights or attention heads to reduce model size without compromising significant accuracy~\cite{han2016deep}.
		\item Quantization: Reducing the precision of the model's parameters (e.g., from FP32 to INT8) to lower memory footprint and increase inference speed.
	\end{itemize}
	
	Prominent examples of SLMs include DistilBERT (66M parameters), TinyBERT, MiniLM, ALBERT, and MobileBERT~\cite{sanh2019distilbert, jiao2020tinybert, wang2020minilm, lan2019albert, sun2020mobilebert}. Prior studies demonstrate that SLMs achieve near-PLM performance on general NLP classification tasks while offering 3--5$\times$ faster inference and 60--70\% reduced memory footprint~\cite{li2023survey, tang2022gal}.
	
	\subsection{Research Gap and Research Questions}
	Despite the extensive use of SLMs in general text classification, their specific application to fake news detection remains limited~\cite{yang2022fake, zhang2023survey}. Existing literature largely focuses on maximizing accuracy using heavy PLMs, often neglecting the constraints of real-world deployment on edge devices. Furthermore, comprehensive analyses of the trade-offs between detection performance and computational efficiency (latency, memory) are lacking in the context of misinformation detection.
	
	This study addresses these gaps by investigating the following research questions: 
	\begin{enumerate}
		\item How effectively can SLMs detect fake news compared to larger PLMs?
		\item How do Parameter-Efficient Fine-Tuning (PEFT) techniques influence SLM performance?
		\item What are the trade-offs between accuracy and computational efficiency in resource-constrained scenarios?
	\end{enumerate}
	
	% SECTION 3: METHODOLOGY
	
	\section{Methodology}
	\label{sec:methodology}
	
	This section details our proposed framework, transforming raw news data into actionable predictions via a modular pipeline consisting of robust preprocessing, diverse SLM architectures, and specialized parameter-efficient fine-tuning strategies.
	
	\subsection{System Overview}
	
	The workflow comprises four sequential stages:
	
	Preprocessing: We construct the input sequence by concatenating the article title and body text, separated by a model-specific separator token (e.g., \texttt{[SEP]} for DistilBERT/MiniLM, \texttt{[SEP]} for ALBERT). Cleaning procedures involve: (1) removing URLs and HTML tags using regular expressions; (2) filtering out samples shorter than 20 characters to eliminate noise; and (3) lowercasing the text to normalize inputs.
	
	Tokenization: Text is tokenized with a static maximum sequence length of 384 tokens. Dynamic padding is applied via \texttt{DataCollatorWithPadding} during batching to optimize GPU utilization.
	
	Model Adaptation: The pre-trained SLM backbone processes the input. We implement a comparative study using three training regimes: Full Fine-Tuning, Low-Rank Adaptation (LoRA), and Prompt Tuning.
	
	Classification: A linear classification head maps the contextual embedding of the special start token (e.g., \texttt{[CLS]}) to the probability distribution over \textit{Real} and \textit{Fake} classes.
	
	The architectural workflow of our proposed framework is illustrated in Fig.~\ref{fig:workflow_diagram}.
	
	\begin{figure}[htbp]
		\centering
		\includegraphics[width=1.0\linewidth]{plots/system_overview_vertical.png}
		\caption{System overview of the proposed SLM-based framework. The pipeline proceeds from unified preprocessing and adaptive encoding (via Full FT or PEFT) to final binary classification.}
		\label{fig:workflow_diagram}
	\end{figure}
	
	% 3.2 MODELS AND FINE-TUNING STRATEGIES
	
	\subsection{Models and Fine-Tuning Strategies}
	\label{subsec:models_strategies}
	
	To evaluate the effectiveness of lightweight architectures in fake news detection, we employ three representative families of Small Language Models (SLMs). These models are selected based on their parameter count, inference efficiency, and widespread adoption in the NLP community.
	
	Unlike standard Large Language Models (LLMs) which demand substantial computational resources, the chosen SLMs offer a balanced trade-off between size and performance:
	
	\begin{itemize}[label=\textbullet]
		\item DistilBERT: A compact version of BERT obtained through knowledge distillation \cite{sanh2019distilbert}. By distilling the teacher model (BERT-base) during pre-training, DistilBERT reduces the number of parameters by 40\% while retaining 97\% of the performance. It is pre-trained on the same corpus as BERT (BookCorpus and English Wikipedia).
		
		\item MiniLM: A lightweight model optimized for speed and memory efficiency. MiniLM utilizes deep self-attention distillation \cite{wang2020minilm}, allowing it to mimic the self-attention modules of a larger teacher model. This results in a highly compact architecture (approximately 33M parameters for the 6-layer version) suitable for edge deployment.
		
		\item ALBERT: An architecture employing cross-layer parameter sharing \cite{lan2019albert} and factorized embedding parameterization to significantly reduce parameters. Although ALBERT-base has a similar architectural depth to BERT, its unique design reduces the total parameter count to approximately 11M, making it the most memory-efficient model in our comparison.
	\end{itemize}
	
	These models contain significantly fewer parameters than standard BERT-base or RoBERTa-base models while retaining strong contextual representation capabilities. Using this diverse set of SLMs supports a broader assessment of the trade-offs between size and performance.\\
	
	We investigate two primary approaches to adapt these pre-trained backbones for the specific task of binary fake news classification.
	\paragraph{Full-Parameter Fine-Tuning.}
	In this traditional approach, all parameters $\theta$ of the pre-trained model are updated. The model is initialized with pre-trained weights, and gradients are backpropagated through the entire network. While effective, this method requires storing a full copy of the model for each task, leading to high storage costs.
	
	\paragraph{PEFT Variants.}
	We employ Parameter-Efficient Fine-Tuning (PEFT) to adapt the models by updating only a small subset of parameters. We implement three distinct variants to cover weight-based, module-based, and input-based adaptation:
	
	\begin{enumerate}[label=\textbullet]
		\item Low-Rank Adaptation (LoRA): 
		LoRA \cite{hu2021lora} injects trainable rank decomposition matrices into the transformer layers while freezing the pre-trained weights $W_0$. For a given layer, the forward pass is modified as:
		\begin{equation}
			h = W_0 x + \Delta W x = W_0 x + \frac{\alpha}{r} BAx
		\end{equation}
		where $B \in \mathbb{R}^{d \times r}$ and $A \in \mathbb{R}^{r \times k}$ are low-rank matrices ($r \ll d$), and $\alpha$ is a scaling factor. We apply LoRA specifically to the Query ($Q$) and Value ($V$) attention matrices.\\
		
		\item Adapters (Bottleneck Adapters): 
		Following the architecture proposed by Houlsby et al. \cite{houlsby2019parameter} , we insert lightweight adapter modules within each transformer block (after the multi-head attention and feed-forward layers). An adapter consists of a down-projection $W_{down}$ to a bottleneck dimension $r$ and an up-projection $W_{up}$:
		\begin{equation}
			\text{Adapter}(h) = W_{up} \cdot \sigma(W_{down} \cdot h) + h
		\end{equation}
		where $\sigma$ is a non-linear activation function. Only the adapter parameters and layer normalization layers are trained.\\
		
		\item Prompt Tuning: 
		Unlike the previous methods that modify the model architecture, Prompt Tuning \cite{lester2021power} optimizes the input space. Let $E \in \mathbb{R}^{n \times d}$ be the embedding sequence of the input text. We introduce a set of $m$ trainable continuous vectors (soft prompts) $P \in \mathbb{R}^{m \times d}$. These prompts are prepended to the input embeddings to form an augmented input $X'$:
		\begin{equation}
			X' = [P; E] = [p_1; p_2; \dots; p_m; e_1; e_2; \dots; e_n]
		\end{equation}
		During training, only the soft prompt vectors $P$ are updated via backpropagation, while the entire pre-trained backbone $\theta$ remains frozen. This represents the most memory-efficient strategy in our study.
	\end{enumerate}
	
	\subsection{Training Procedure}
	\label{subsec:training_procedure}
	
	The training process is standardized across all models and datasets to ensure a fair comparison. The optimization objective is to minimize the empirical risk on the training set.
	
	\begin{itemize}[label=\textbullet]
		\item Loss Function: We utilize the Cross-Entropy Loss to measure the discrepancy between the predicted probability distribution and the true labels. To address class imbalance (specifically in the FakeNewsNet dataset), we employ a \textit{Weighted Cross-Entropy Loss}:
		\begin{equation}
			\mathcal{L} = - \frac{1}{N} \sum_{i=1}^{N} w_{y_i} \log(p(y_i | x_i))
		\end{equation}
		where $w_{y_i}$ is the inverse class frequency weight for class $y_i$.
		
		\item Optimizer and Scheduling: We use the AdamW optimizer with a decoupled weight decay of $0.01$ to prevent overfitting. A linear learning rate scheduler with a warmup period (10\% of total steps) is applied. The initial learning rate is set to $2\times10^{-5}$ for full fine-tuning and $1\times10^{-3}$ for PEFT methods (LoRA/Adapters), as PEFT typically requires larger learning rates.\\
		
		\item Training Configuration:
		
		Batch Size: Set to 16 or 32 depending on GPU memory constraints.
		
		Epochs: Models are trained for 3 to 5 epochs.
		
		Regularization: We apply dropout with a probability of 0.1 and use Early Stopping based on the Validation $F_{1}$-score (patience = 3 epochs) to determine the optimal checkpoint.
	\end{itemize}
	
	\subsection{Classification Layer}
	\label{subsec:classification_layer}
	
	The classification head is appended to the final layer of the SLM backbone. We extract the hidden state of the special classification token (\texttt{[CLS]}) from the last transformer layer, denoted as $h_{\texttt{[CLS]}} \in \mathbb{R}^d$. This vector serves as the aggregate representation of the entire news article.
	
	The vector $h_{\texttt{[CLS]}}$ is then passed through a fully connected (dense) layer followed by a Softmax activation function to produce the probability distribution over the two classes (Fake vs. Real):
	\begin{equation}
		\hat{y} = \text{Softmax}(W_{cls} \cdot h_{\texttt{[CLS]}} + b_{cls})
	\end{equation}
	where $W_{cls} \in \mathbb{R}^{2 \times d}$ and $b_{cls} \in \mathbb{R}^2$ are the trainable parameters of the classifier.
	
	The complete training procedure, encompassing data standardization and strategy selection, is summarized in Algorithm \ref{alg:general_framework}.
	
	\begin{algorithm}[H]
		\caption{General Training Framework for SLM-based Fake News Detection}
		\label{alg:general_framework}
		\begin{algorithmic}[1]
			\Require 
			Dataset $\mathcal{D}$ (WELFake, FakeNewsNet, LIAR); 
			Backbone $\mathcal{M}$; Strategy $\mathcal{S}$; Hyperparams $\eta, \mathcal{B}, E$.
			\Ensure Optimized Parameters $\theta^*$.
			
			\Statex \textbf{// Phase 1: Context-Aware Preprocessing}
			\For{each sample $(x_i, y_i) \in \mathcal{D}$}
			\If{Dataset is \textbf{LIAR}}
			\State \textit{Fusion:} $raw\_text \leftarrow \text{Statement} \oplus \texttt{[SEP]} \oplus \text{Context} \oplus \texttt{[SEP]} \oplus \text{Speaker}$
			\Else \Comment{WELFake / FakeNewsNet}
			\State \textit{Concat:} $raw\_text \leftarrow \text{Title} \oplus \texttt{[SEP]} \oplus \text{BodyText}$
			\EndIf
			\State $x_i \leftarrow \text{Clean}(raw\_text)$; $T_i \leftarrow \text{Tokenize}(x_i)$
			\EndFor
			
			\Statex \textbf{// Phase 2: Model Configuration (PEFT Selection)}
			\State Load pre-trained weights $\theta$.
			\If{$\mathcal{S} == \text{LoRA}$}
			\State Inject matrices $A, B$ into Attention; Freeze $\theta$.
			\ElsIf{$\mathcal{S} == \text{Adapter}$}
			\State Insert Bottleneck Layers; Freeze $\theta$.
			\ElsIf{$\mathcal{S} == \text{PromptTuning}$}
			\State Prepend Soft Prompts $P$; Freeze $\theta$.
			\Else
			\State Unfreeze all parameters (Full FT).
			\EndIf
			
			\Statex \textbf{// Phase 3: Training}
			\State Optimize $\theta_{train}$ using Weighted Cross-Entropy.
			\State \Return $\theta^*$.
		\end{algorithmic}
	\end{algorithm}
	
	
	% SECTION 4: EXPERIMENTAL SETUP
	
	\section{Experimental Setup}
	\label{sec:experimental_setup}
	
	This section details the datasets, baseline models, evaluation metrics, and implementation specifics used to validate the proposed framework.
	
	\subsection{Datasets}
	To evaluate the robustness of our approach across different scales and domains, we utilize three benchmark datasets. Table~\ref{tab:dataset_stats} summarizes the effective statistics after our rigorous preprocessing pipeline.
	
	\begin{itemize}[label=\textbullet]
		\item WELFake \cite{verma2021welfake}: A large-scale general news dataset. From the initial 72,134 articles, our cleaning process retained 63,323 high-quality samples. The class distribution is fairly balanced (54.5\% Fake vs. 45.5\% Real), requiring only mild class weighting ($w_{fake} \approx 0.92$) during training.\\
		
		\item FakeNewsNet \cite{shu2020fakenewsnet}: Representing a challenging social media context (PolitiFact/GossipCop), this dataset originally contained 23,196 samples. After filtering for valid text content compatible with transformer tokenization, we obtained 21,287 effective samples. It exhibits severe class imbalance with only 24.2\% Fake news. We address this by applying strong inverse frequency weights ($w_{fake} \approx 2.06, w_{real} \approx 0.66$) to penalize false negatives on the minority class.\\
		
		\item LIAR \cite{wang2017liar}: A widely recognized benchmark for short-text fact-checking. We aggregated the original six labels into a binary format (Fake vs. Real), resulting in a total of 22,962 samples. The dataset is split into Train (18,369), Validation (2,296), and Test (2,297). The distribution shows a moderate imbalance (39.4\% Fake vs. 60.6\% Real), which we handle using calculated class weights ($w_{fake} \approx 1.27, w_{real} \approx 0.82$). Given the brevity of the statements, we applied feature engineering (Metadata Fusion) to enrich the input context.
	\end{itemize}
	
	\begin{table}[htbp]
		\centering
		\caption{Effective dataset statistics post-preprocessing. The \textit{Effective Samples} column reflects the data actually used for training and evaluation after cleaning and label aggregation.}
		\label{tab:dataset_stats}
		\resizebox{\textwidth}{!}{
			\begin{tabular}{l|c|c|c|c}
				\toprule
				\textbf{Dataset} & \textbf{Effective Samples} & \textbf{Train / Val / Test} & \textbf{Balance (Fake:Real)} & \textbf{Class Weights} \\ \midrule
				WELFake & 63,323 & 47.5k / 7.9k / 7.9k & 54.5 : 45.5 & $0.92 : 1.10$ \\
				FakeNewsNet & 21,287 & 16.0k / 2.1k / 3.2k & 24.2 : 75.8 & $2.06 : 0.66$ \\ 
				LIAR & 22,962 & 18.4k / 2.3k / 2.3k & 39.4 : 60.6 & $1.27 : 0.82$ \\
				\bottomrule
			\end{tabular}
		}
	\end{table}
	
	% 4.2 BASELINES AND COMPARISON MODELS
	
	\subsection{Baselines and Comparison Models}
	We benchmark our proposed SLM strategies against two categories of models to establish a comprehensive performance spectrum.
	
	To evaluate the efficiency of traditional methods, we employ:
	
	Logistic Regression (LR): Uses TF-IDF features (top 50k n-grams). It serves as a high-speed, low-resource baseline.
	
	Support Vector Machine (SVM): Implemented using LinearSVC with squared hinge loss, known for efficacy in high-dimensional text classification.
	
	Bi-LSTM: A Deep Learning baseline using Bidirectional LSTMs with pre-trained word embeddings to capture sequential dependencies.
	
	To establish an upper bound for detection accuracy, we use full-scale transformer models:
	BERT-base-uncased \cite{devlin2018bert}: The standard bidirectional transformer (110M parameters).
	
	RoBERTa-base \cite{liu2019roberta}: A robustly optimized BERT variant (125M parameters) that typically achieves state-of-the-art results on NLP tasks.
	
	
	We hypothesize that Small Language Models (DistilBERT, MiniLM, ALBERT) can achieve competitive performance (within 1-2\% of Teachers) while significantly reducing computational costs. This "sweet spot" is critical for deployment in resource-constrained environments where Classical ML may lack nuance and Large Models are too heavy.
	
	% 4.3 EVALUATION METRICS
	
	\subsection{Evaluation Metrics}
	Performance is assessed using standard classification metrics:
	\begin{itemize}[label=\textbullet]
		\item Accuracy, Precision, Recall, $F_{1}$-Score: We report the weighted average for these metrics to account for class distribution.
		\item AUC (Area Under the Curve): Used to evaluate the model's ability to distinguish between classes across different decision thresholds.
	\end{itemize}
	For efficiency analysis, we measure:
	\begin{itemize}[label=\textbullet]
		\item Inference Speed: The number of samples processed per second (samples/s) on a GPU.
		\item Training Time: The total time required for model convergence.
	\end{itemize}
	
	% 4.4 IMPLEMENTATION DETAILS
	
	\subsection{Implementation Details}
	All experiments were conducted in a standardized environment to ensure reproducibility.
	
	Computing Environment: Experiments were executed on Google Colab Pro utilizing a single NVIDIA Tesla T4 GPU (16GB VRAM) and 12GB of system RAM.
	
	Software Stack: We used Python 3.10, PyTorch 2.0, and the Hugging Face \texttt{transformers} \cite{wolf2019huggingface} and \texttt{peft} libraries. Classical ML models utilized \texttt{scikit-learn}.
	
	Hyperparameter Configuration:
	Table~\ref{tab:hyperparams} details the specific settings derived from grid search. Notably, PEFT methods (LoRA/Prompt Tuning) utilize a higher learning rate ($1 \times 10^{-3}$) compared to Full Fine-Tuning ($2 \times 10^{-5}$) to ensure effective adaptation of the small trainable parameter set.
	
	\begin{table}[htbp]
		\centering
		\caption{Hyperparameter settings for different training strategies.}
		\label{tab:hyperparams}
		\begin{tabular}{l|c|c|c}
			\toprule
			\textbf{Parameter} & \textbf{Full Fine-Tuning} & \textbf{LoRA} & \textbf{Prompt Tuning} \\ \midrule
			Learning Rate & $2 \times 10^{-5}$ & $1 \times 10^{-3}$ & $1 \times 10^{-2}$ \\
			Batch Size & 16 & 32 & 32 \\
			Epochs & 3 & 5 & 5 \\
			Optimizer & AdamW & AdamW & AdamW \\
			Weight Decay & 0.01 & 0.01 & 0.01 \\
			Scheduler & Linear Warmup & Linear Warmup & Linear Warmup \\
			\textit{Specifics} & N/A & $r=16, \alpha=32$ & $v\_tokens=8$ \\
			\bottomrule
		\end{tabular}
	\end{table}
	
	
	% SECTION 5: RESULTS 
	
	\section{Results}
	\label{sec:results_discussion}
	
	\subsection{Experimental Results}
	We evaluate the framework across three benchmarks: Large-scale Balanced (WELFake), High Imbalance (FakeNewsNet), and Short-text (LIAR).
	
	% --- TABLE 3: WELFAKE ---
	Table~\ref{tab:welfake_results} summarizes the results on WELFake.
	\begin{itemize}[label=\textbullet]
		\item High Consistency: All strategies achieved $>96\%$ $F_{1}$. Full Fine-Tuning remains the gold standard ($\sim$98.3\%), but PEFT methods are highly competitive.
		\item Adapter Stability: Bottleneck Adapters performed consistently well ($\sim$97\%), bridging the gap between LoRA and Full FT.
	\end{itemize}
	
	\begin{table}[htbp]
		\centering
		\small \setlength{\tabcolsep}{3.5pt} \renewcommand{\arraystretch}{1.2}
		\caption{Results on WELFake. Adapters achieve high accuracy with moderate speed.}
		\label{tab:welfake_results}
		\begin{tabular}{l|l|cccc|r}
			\toprule
			\textbf{Group} & \textbf{Method} & \textbf{Acc} & \textbf{Prec} & \textbf{Rec} & \textbf{$F_{1}$} & \textbf{Speed} \\ \midrule
			\multirow{3}{*}{\textit{Baselines}} 
			& Logistic Reg. & 96.1 & 96.1 & 96.1 & 96.1 & 819,818 \\
			& LinearSVC & 97.7 & 97.7 & 97.7 & 97.7 & 105,858 \\ 
			& Bi-LSTM & 97.9 & 97.9 & 97.9 & 97.9 & 3,261 \\ \midrule
			\multirow{2}{*}{\textit{Teachers}} 
			& BERT (Full) & 98.7 & 98.7 & 98.7 & 98.7 & 178 \\
			& RoBERTa (Full) & \textbf{99.4} & \textbf{99.4} & \textbf{99.4} & \textbf{99.4} & 187 \\ \midrule
			\multirow{12}{*}{\textit{SLMs}} 
			& DistilBERT (Full) & 98.3 & 98.3 & 98.3 & 98.3 & 285 \\
			& DistilBERT (LoRA) & 96.2 & 96.3 & 96.2 & 96.2 & 285 \\
			& DistilBERT (Adapt) & 97.0 & 97.0 & 97.0 & 97.0 & 205 \\
			& DistilBERT (PT) & 96.8 & 96.8 & 96.8 & 96.8 & 327 \\ \cmidrule{2-7}
			& MiniLM (Full) & 98.3 & 98.3 & 98.3 & 98.3 & 519 \\
			& MiniLM (LoRA) & 95.0 & 95.0 & 95.0 & 95.0 & 519 \\
			& MiniLM (Adapt) & 96.3 & 96.3 & 96.3 & 96.3 & 299 \\
			& MiniLM (PT) & 94.8 & 94.9 & 94.8 & 94.8 & 523 \\ \cmidrule{2-7}
			& ALBERT (Full) & 97.7 & 97.7 & 97.7 & 97.7 & 94 \\
			& ALBERT (LoRA) & 95.6 & 95.6 & 95.6 & 95.6 & 94 \\
			& ALBERT (Adapt) & 97.4 & 97.4 & 97.4 & 97.4 & 85 \\
			& ALBERT (PT) & 96.2 & 96.2 & 96.2 & 96.2 & 99 \\
			\bottomrule
		\end{tabular}
	\end{table}
	
	\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=1.0\linewidth]{plots/WELFake_BarChart.png}
        \caption{Bar chart showing F1 scores of different models on the WELFake dataset~\cite{verma2021welfake}.}
        \label{fig:welfake_barchart}
    \end{subfigure}
    \vspace{10pt}
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=1.0\linewidth]{plots/WELFake_ScatterPlot.png}
        \caption{Scatter plot of inference speed vs. accuracy for models on the WELFake dataset.}
        \label{fig:welfake_scatter}
    \end{subfigure}
    \caption{Results on the WELFake dataset~\cite{verma2021welfake}. (a) F1 scores across model families. (b) Speed-accuracy trade-off visualization.}
    \label{fig:res_welfake}
\end{figure}

% --- TABLE 4: FAKENEWSNET ---
\begin{table}[htbp]
    \centering
    \small \setlength{\tabcolsep}{3.5pt} \renewcommand{\arraystretch}{1.2}
    \caption{Results on FakeNewsNet. Adapters outperform Prompt Tuning on imbalanced data.}
    \label{tab:fakenewsnet_results}
    \begin{tabular}{l|l|cccc|r}
        \toprule
        \textbf{Group} & \textbf{Method} & \textbf{Acc} & \textbf{Prec} & \textbf{Rec} & \textbf{$F_{1}$} & \textbf{Speed} \\ \midrule
        \multirow{3}{*}{\textit{Baselines}} 
        & Logistic Reg. & 84.3 & 83.8 & 84.3 & 83.9 & 206,285 \\
        & LinearSVC & 84.3 & 83.8 & 84.3 & 83.9 & 154,346 \\ 
        & Bi-LSTM & 77.9 & 81.2 & 77.9 & 78.9 & 4,272 \\ \midrule
        \multirow{2}{*}{\textit{Teachers}} 
        & BERT (Full) & 83.6 & 83.7 & 83.6 & 83.6 & 1,300 \\
        & \textbf{RoBERTa (Full)} & \textbf{84.6} & \textbf{85.9} & \textbf{84.6} & \textbf{85.0} & 675 \\ \midrule
        \multirow{12}{*}{\textit{SLMs}} 
        & DistilBERT (Full) & 83.8 & 84.5 & 83.8 & 84.1 & 1,045 \\
        & DistilBERT (LoRA) & 82.7 & 83.2 & 82.7 & 82.9 & 2,432 \\
        & DistilBERT (Adapt) & 81.4 & 82.2 & 81.4 & 81.8 & 207 \\
        & DistilBERT (PT) & 75.8 & 57.5 & 75.8 & 65.4 & 2,711 \\ \cmidrule{2-7}
        & MiniLM (Full) & 80.6 & 82.5 & 80.6 & 81.2 & 3,210 \\
        & MiniLM (LoRA) & 81.1 & 83.0 & 81.1 & 81.7 & 2,715 \\
        & MiniLM (Adapt) & 79.0 & 81.8 & 79.0 & 79.9 & 302 \\
        & MiniLM (PT) & 73.7 & 77.4 & 73.7 & 74.9 & 2,980 \\ \cmidrule{2-7}
        & ALBERT (Full) & 81.4 & 82.8 & 81.4 & 81.9 & 1,237 \\
        & ALBERT (LoRA) & 75.8 & 57.4 & 75.8 & 65.3 & 1,055 \\
        & ALBERT (Adapt) & 77.5 & 81.1 & 77.5 & 78.6 & 85 \\
        & ALBERT (PT) & 76.1 & 78.8 & 76.1 & 77.1 & 939 \\
        \bottomrule
    \end{tabular}
\end{table}

Table~\ref{tab:fakenewsnet_results} shows the results on the imbalanced dataset.
\begin{itemize}[label=\textbullet]
    \item Adapter Resilience: Unlike Prompt Tuning which dropped to $\sim$65\%, Adapters maintained respectable performance ($\sim$79-82\% $F_{1}$), proving more robust to class imbalance than input-based tuning.
\end{itemize}

\begin{figure}[htbp]
    \centering
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=1.0\linewidth]{plots/FakeNewsNet_BarChart.png}
        \caption{Bar chart of model performance on the FakeNewsNet dataset~\cite{shu2017fake}.}
        \label{fig:fakenewsnet_barchart}
    \end{subfigure}
    \vspace{10pt}
    \begin{subfigure}[t]{\textwidth}
        \centering
        \includegraphics[width=1.0\linewidth]{plots/FakeNewsNet_ScatterPlot.png}
        \caption{Scatter plot of computational efficiency metrics on the FakeNewsNet dataset.}
        \label{fig:fakenewsnet_scatter}
    \end{subfigure}
    \caption{Results on the FakeNewsNet dataset~\cite{shu2017fake}. (a) Performance comparison. (b) Efficiency metrics.}
    \label{fig:res_fakenewsnet}
\end{figure}
	A key finding is the superior stability of Bottleneck Adapters on the challenging LIAR dataset. While LoRA and Full FT suffered from model collapse (converging to majority class), Adapters achieved the highest accuracy across all experiments ($\sim$68\%). We hypothesize that the structural constraint of adapters acts as a strong regularizer, preventing the model from overfitting to the noise in short texts while still allowing sufficient adaptation.
	
	While Adapters offer high accuracy, they introduce a noticeable latency penalty. For example, MiniLM-Adapter processes $\sim$300 samples/s compared to $\sim$520 samples/s for Full FT/LoRA. This is due to the serial insertion of extra layers which breaks the fusion optimization of the transformer backbone.
	
	% SECTION 6: CONCLUSION & FUTURE WORK
	
	% \section{Conclusion}
	\clearpage
	\section{Conclusion}
	\label{sec:conclusion}
	
	This study established a comprehensive framework for scalable fake news detection, rigorously evaluating the interplay between Small Language Models (SLMs) and Parameter-Efficient Fine-Tuning (PEFT) strategies. Across three diverse benchmarks, we demonstrated that efficiency does not necessarily come at the cost of accuracy, provided the adaptation strategy matches the data characteristics.
	
	Our experiments yielded four pivotal insights:
	\begin{enumerate}
		\item SLM Superiority on Long Context: On the balanced WELFake dataset, distilled models proved exceptionally capable. DistilBERT (Full FT) achieved a state-of-the-art $F_1$-score of 99.09\%, surpassing the teacher model RoBERTa-base (99.37\%), challenging the assumption that larger parameter counts are always superior for binary classification tasks.
		
		\item The "Adapter" Breakthrough: A critical contribution of this work is identifying the stability of Bottleneck Adapters on short, noisy text. While LoRA and Full Fine-Tuning suffered from "Model Collapse" on the LIAR dataset (converging to majority class with $\sim$45.7\% F1), Adapters successfully captured decision boundaries, achieving $\sim$68\% F1, thereby outperforming even the BERT-base teacher.
		
		\item Efficiency Sweet Spot: MiniLM emerged as the optimal solution for real-time systems. It matches the accuracy of large transformers while delivering a 2.7$\times$ speedup (processing $>$350 samples/s), making it viable for high-throughput edge deployment.
		
		\item PEFT Sensitivity: We observed that input-based tuning (Prompt Tuning) is highly sensitive to class imbalance, showing significant performance drops on FakeNewsNet compared to weight-based methods (LoRA/Full FT).
	\end{enumerate}
	
	
	This research validates a tiered deployment architecture for combating misinformation. By leveraging MiniLM for speed and Adapters for robustness on noisy data, organizations can deploy sophisticated detection systems on resource-constrained hardware (e.g., standard CPUs or mobile edge devices) without relying on massive GPU clusters, thus democratizing access to AI-driven truth verification.
	
	
	To further enhance this framework, we propose three strategic avenues:
	\begin{itemize}[label=\textbullet]
		\item Multimodal Integration: Since modern misinformation often exploits visual cues, future work will extend our SLM backbones with lightweight vision encoders (e.g., MobileViT) to process image-text pairs efficiently.
		
		\item Explainability Modules: To foster user trust, we aim to integrate lightweight interpretability layers (such as attention rollout or LIME) that can pinpoint specific phrases or patterns triggering the "Fake" classification.
		
		\item Domain Adaptation: Misinformation topics evolve rapidly (e.g., from health crises to elections). We plan to explore Dynamic Adapter Fusion, allowing the system to instantly switch between topic-specific adapters without retraining the core backbone, ensuring rapid response to emerging threats.
	\end{itemize}
	
	
	
	
	
	\bibliographystyle{unsrt}
	\bibliography{ref}
	
\end{document}